<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Alt Text Generator</title>

<style>
  * {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }

  body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    align-items: center;
    padding: 20px;
  }

  .container {
    background: white;
    border-radius: 16px;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    padding: 40px;
    max-width: 700px;
    width: 100%;
    margin-top: 20px;
  }

  h1 {
    color: #333;
    margin-bottom: 10px;
    text-align: center;
    font-size: 2em;
  }

  .subtitle {
    text-align: center;
    color: #666;
    margin-bottom: 30px;
    font-size: 0.9em;
  }

  .input-section {
    margin-bottom: 20px;
  }

  .input-group {
    display: flex;
    gap: 10px;
    margin-bottom: 15px;
  }

  #urlInput {
    flex: 1;
    padding: 12px 16px;
    border: 2px solid #e0e0e0;
    border-radius: 8px;
    font-size: 1em;
  }

  button {
    padding: 12px 24px;
    background: #667eea;
    color: white;
    border: none;
    border-radius: 8px;
    font-size: 1em;
    cursor: pointer;
    font-weight: 600;
    transition: background 0.3s;
  }

  button:hover {
    background: #5a67d8;
  }

  button:disabled {
    background: #ccc;
    cursor: not-allowed;
  }

  .paste-hint {
    text-align: center;
    color: #999;
    font-size: 0.9em;
    padding: 10px;
    background: #f8f9fa;
    border-radius: 8px;
    margin-bottom: 20px;
  }

  .preview-section {
    text-align: center;
    margin: 20px 0;
  }

  #preview {
    max-width: 100%;
    max-height: 400px;
    border-radius: 8px;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    display: none;
  }

  #preview.visible {
    display: block;
  }

  .result-label {
    font-weight: 600;
    color: #333;
    margin-bottom: 10px;
    font-size: 1.1em;
  }

  #altText {
    background: #f8f9fa;
    padding: 20px;
    border-radius: 8px;
    border-left: 4px solid #667eea;
    line-height: 1.6;
    color: #333;
    font-size: 1em;
    min-height: 120px;
  }

  #altText.loading {
    color: #667eea;
    font-style: italic;
  }

  .copy-btn {
    margin-top: 10px;
    width: 100%;
    background: #28a745;
    display: none;
  }

  .copy-btn:hover {
    background: #218838;
  }

  .copy-btn.visible {
    display: block;
  }

  .error {
    color: #e53e3e;
    background: #fed7d7;
    border-left-color: #e53e3e;
  }

  .model-select {
    margin-bottom: 20px;
    padding: 10px 15px;
    border: 2px solid #e0e0e0;
    border-radius: 8px;
    font-size: 1em;
    width: 100%;
    background: white;
  }

  .model-info {
    text-align: center;
    color: #666;
    font-size: 0.8em;
    margin-top: 5px;
    margin-bottom: 15px;
  }
</style>
</head>

<body>

<div class="container">
  <h1>üñºÔ∏è Advanced Alt Text Generator</h1>
  <p class="subtitle">Generate descriptive sentence-based alt text for images</p>

  <select id="modelSelect" class="model-select">
    <option value="caption">Sentence Description Model (Recommended)</option>
    <option value="object">Object Detection Only</option>
  </select>
  <div class="model-info" id="modelInfo">Generates full sentence descriptions</div>

  <div class="input-section">
    <div class="input-group">
      <input type="text" id="urlInput" placeholder="Paste image URL here">
      <button id="loadUrl">Load</button>
    </div>
    <div class="paste-hint">
      üí° You can also paste an image directly from your clipboard (Ctrl+V / Cmd+V)
    </div>
  </div>

  <div class="preview-section">
    <img id="preview" alt="Preview">
  </div>

  <div class="result-section">
    <div class="result-label">Generated Alt Text:</div>
    <div id="altText" class="loading">Loading AI model...</div>
    <button id="copyBtn" class="copy-btn">Copy Alt Text</button>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.6.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.1.0/dist/mobilenet.min.js"></script>

<script>
const preview = document.getElementById('preview');
const altTextDiv = document.getElementById('altText');
const urlInput = document.getElementById('urlInput');
const loadUrlBtn = document.getElementById('loadUrl');
const copyBtn = document.getElementById('copyBtn');
const modelSelect = document.getElementById('modelSelect');
const modelInfo = document.getElementById('modelInfo');

let mobilenetModel;
let currentAltText = '';
let currentModelType = 'caption';

// Update model info based on selection
modelSelect.onchange = () => {
  currentModelType = modelSelect.value;
  if (currentModelType === 'caption') {
    modelInfo.textContent = 'Generates full sentence descriptions';
  } else {
    modelInfo.textContent = 'Lists detected objects only';
  }
};

// Load AI model
(async function loadModel() {
  try {
    mobilenetModel = await mobilenet.load();
    altTextDiv.textContent = 'Model ready. Load or paste an image.';
    altTextDiv.className = '';
  } catch (error) {
    altTextDiv.textContent = 'Error loading model. Please refresh the page.';
    altTextDiv.className = 'error';
  }
})();

// Generate sentence-based description
async function generateSentenceDescription(img) {
  const predictions = await mobilenetModel.classify(img);

  if (!predictions.length) {
    return 'Unable to generate description for this image.';
  }

  // Format predictions nicely
  const formatName = (name) => {
    return name
      .replace(/_/g, ' ')
      .replace(/,/g, '')
      .toLowerCase()
      .replace(/\b\w/g, char => char.toUpperCase());
  };

  const mainObject = formatName(predictions[0].className);
  const confidence = (predictions[0].probability * 100).toFixed(0);

  // Create a natural sentence based on the top predictions
  let sentence = '';
  
  if (predictions.length >= 3) {
    const object1 = formatName(predictions[0].className);
    const object2 = formatName(predictions[1].className);
    const object3 = formatName(predictions[2].className);
    
    const sentenceTemplates = [
      `A photo featuring ${object1}, along with ${object2} and ${object3}.`,
      `An image showing ${object1} in a scene that includes ${object2} and ${object3}.`,
      `This picture contains ${object1}, with visible elements of ${object2} and ${object3}.`,
      `Photograph of ${object1} alongside ${object2} and ${object3}.`
    ];
    
    sentence = sentenceTemplates[Math.floor(Math.random() * sentenceTemplates.length)];
    
  } else if (predictions.length >= 2) {
    const object1 = formatName(predictions[0].className);
    const object2 = formatName(predictions[1].className);
    
    const sentenceTemplates = [
      `A photo of ${object1} and ${object2}.`,
      `An image showing ${object1} with ${object2}.`,
      `This picture contains both ${object1} and ${object2}.`,
      `Photograph featuring ${object1} alongside ${object2}.`
    ];
    
    sentence = sentenceTemplates[Math.floor(Math.random() * sentenceTemplates.length)];
    
  } else {
    const object1 = formatName(predictions[0].className);
    
    const sentenceTemplates = [
      `A photo of ${object1}.`,
      `An image showing ${object1}.`,
      `This picture contains ${object1}.`,
      `Photograph featuring ${object1}.`
    ];
    
    sentence = sentenceTemplates[Math.floor(Math.random() * sentenceTemplates.length)];
  }

  // Add context about setting if we have confidence about it
  const confidenceAdjectives = confidence > 70 ? 'clearly visible' : 
                               confidence > 40 ? 'apparent' : 
                               'possibly present';
  
  sentence = sentence.replace(' of ', ` of ${confidenceAdjectives} `);
  
  // Add additional description based on detected objects
  const descriptivePhrases = {
    'dog': 'likely a pet or animal companion',
    'cat': 'likely a domestic pet',
    'person': 'human subject',
    'car': 'vehicle in the scene',
    'building': 'architectural structure',
    'tree': 'natural vegetation',
    'flower': 'botanical element',
    'food': 'culinary item',
    'book': 'reading material',
    'computer': 'electronic device'
  };

  // Check if we can add more context
  for (const [key, phrase] of Object.entries(descriptivePhrases)) {
    if (predictions[0].className.toLowerCase().includes(key)) {
      sentence += ` The ${key} appears to be ${phrase}.`;
      break;
    }
  }

  return sentence;
}

// Generate object list description (original style)
async function generateObjectList(img) {
  const predictions = await mobilenetModel.classify(img);

  if (!predictions.length) {
    return 'Unable to generate alt text.';
  }

  const main = predictions[0].className.replace(/_/g, ' ');
  let description = main;

  if (predictions.length > 1) {
    const others = predictions.slice(1, 3).map(p => p.className.replace(/_/g, ' '));
    description += `, possibly including ${others.join(' or ')}`;
  }

  return description.charAt(0).toUpperCase() + description.slice(1);
}

// Main alt text generation function
async function generateAltText(img) {
  altTextDiv.textContent = 'Analyzing image...';
  altTextDiv.className = 'loading';
  copyBtn.classList.remove('visible');
  loadUrlBtn.disabled = true;
  loadUrlBtn.textContent = 'Processing...';

  try {
    let description;
    
    if (currentModelType === 'caption') {
      description = await generateSentenceDescription(img);
    } else {
      description = await generateObjectList(img);
    }
    
    currentAltText = description;
    altTextDiv.textContent = description;
    altTextDiv.className = '';
    copyBtn.classList.add('visible');
    
  } catch (error) {
    console.error('Error generating alt text:', error);
    altTextDiv.textContent = 'Error generating description. Please try another image.';
    altTextDiv.className = 'error';
  } finally {
    loadUrlBtn.disabled = false;
    loadUrlBtn.textContent = 'Load';
  }
}

// Load image from URL
loadUrlBtn.onclick = () => {
  if (!urlInput.value.trim()) {
    altTextDiv.textContent = 'Please enter an image URL.';
    altTextDiv.className = 'error';
    return;
  }
  
  preview.src = urlInput.value;
  preview.onload = () => {
    preview.classList.add('visible');
    generateAltText(preview);
  };
  preview.onerror = () => {
    altTextDiv.textContent = 'Failed to load image. Please check the URL.';
    altTextDiv.className = 'error';
    preview.classList.remove('visible');
    loadUrlBtn.disabled = false;
    loadUrlBtn.textContent = 'Load';
  };
};

// Paste image
window.addEventListener('paste', e => {
  for (const item of e.clipboardData.items) {
    if (item.type.startsWith('image')) {
      const file = item.getAsFile();
      const reader = new FileReader();
      reader.onload = e => {
        preview.src = e.target.result;
        preview.classList.add('visible');
        preview.onload = () => generateAltText(preview);
      };
      reader.readAsDataURL(file);
      break;
    }
  }
});

// Copy alt text
copyBtn.onclick = () => {
  navigator.clipboard.writeText(currentAltText)
    .then(() => {
      copyBtn.textContent = '‚úì Copied!';
      setTimeout(() => copyBtn.textContent = 'Copy Alt Text', 2000);
    })
    .catch(err => {
      console.error('Failed to copy: ', err);
      copyBtn.textContent = 'Failed to copy';
      setTimeout(() => copyBtn.textContent = 'Copy Alt Text', 2000);
    });
};

// Press Enter in URL input to load
urlInput.addEventListener('keypress', (e) => {
  if (e.key === 'Enter') {
    loadUrlBtn.click();
  }
});

// Reset copy button text when copying again
copyBtn.addEventListener('mouseenter', () => {
  if (copyBtn.textContent === '‚úì Copied!') {
    copyBtn.textContent = 'Copy Alt Text';
  }
});
</script>

</body>
</html>